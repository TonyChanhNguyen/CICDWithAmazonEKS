[
{
	"uri": "/2-prerequiste/2.1-createcloud9workspace/",
	"title": "Create Cloud9 workspace",
	"tags": [],
	"description": "",
	"content": "Create Cloud9 workspace   Go to Cloud9 at region ap-southeast-1.\n  Click on Create environment.   At Create environment page, input FCJ-Workspace at Name field.\n  Input Workspace for hands on workshop at Description field.\n  At Environment type field, keep default New EC2 instance.\n  At Instance type field, select Additional instance types.\n  At Additional instance types field, select t3.large.   Scroll down to the end of page and click on Create.   The workspace instance is being created.   It will take you about 2 minutes for the instance is created successfully.\n  After the instance is created successfully, click on Open to start your workspace.   "
},
{
	"uri": "/3-eksstoragewithebs/3.1-installcsidriver/",
	"title": "Install Amazon EBS CSI Driver",
	"tags": [],
	"description": "",
	"content": "The Amazon Elastic Block Store (Amazon EBS) Container Storage Interface (CSI) driver manages the lifecycle of Amazon EBS volumes as storage for the Kubernetes Volumes that you create. The Amazon EBS CSI driver makes Amazon EBS volumes for these types of Kubernetes volumes: generic ephemeral volumes and persistent volumes.\nCreate IAM Policy The Amazon EBS CSI plugin requires IAM permissions to make calls to AWS APIs on your behalf.\n  Go to IAM.\n  Select Policies section.\n  Click on Create policy.   At Policy editor field, select JSON tab.\n  Then, paste the below JSON.\n  {\r\u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;,\r\u0026#34;Statement\u0026#34;: [\r{\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34;: [\r\u0026#34;ec2:AttachVolume\u0026#34;,\r\u0026#34;ec2:CreateSnapshot\u0026#34;,\r\u0026#34;ec2:CreateTags\u0026#34;,\r\u0026#34;ec2:CreateVolume\u0026#34;,\r\u0026#34;ec2:DeleteSnapshot\u0026#34;,\r\u0026#34;ec2:DeleteTags\u0026#34;,\r\u0026#34;ec2:DeleteVolume\u0026#34;,\r\u0026#34;ec2:DescribeInstances\u0026#34;,\r\u0026#34;ec2:DescribeSnapshots\u0026#34;,\r\u0026#34;ec2:DescribeTags\u0026#34;,\r\u0026#34;ec2:DescribeVolumes\u0026#34;,\r\u0026#34;ec2:DetachVolume\u0026#34;\r],\r\u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;\r}\r]\r}  Then, click on Next.   Input Amazon_EBS_CSI_Driver as Policy name.\n  Input Policy for EC2 Instances to access Elastic Block Store as Description - optional.\n  Click on Create policy.   Get the IAM role Worker Nodes using  At Cloud9 Terminal, using below command to find out IAM role name that Worker Nodes using.  kubectl -n kube-system describe configmap aws-auth Verify the value of rolearn to find out the IAM Role name. Example: In this case, the IAM Role name is eksctl-fcj-storage-cluster-nodegro-NodeInstanceRole-dN18fcwv9euu.\nAssociate policy to IAM Role   Go to IAM Role.\n  At Search feature, input the IAM Role name you had found out.\n  Click on it.   Click on Attach policies of Add permissions feature.   Search the policy name Amazon_EBS_CSI_Driver.\n  Select the result.\n  Click on Add permissions.   Deploy Amazon EBS CSI Driver  At Cloud9 Terminal, execute below command.  kubectl apply -k \u0026#34;github.com/kubernetes-sigs/aws-ebs-csi-driver/deploy/kubernetes/overlays/stable/?ref=master\u0026#34; Verify the result. Make sure that there are ebs-csi pods are running at namespace kube-system.  kubectl get pods -n kube-system You had installed Amazon EBS CSI Driver successfully, move to next step to demonstrate how to use it to deploy EBS Storage for Amazon EKS Cluster. "
},
{
	"uri": "/1-introduce/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "Before we dive into the implementation, below is a summary of the two AWS storage services we\u0026rsquo;ll utilize and integrate with EKS:\n Amazon Elastic Block Store (supports EC2 only): a block storage service that provides direct access from EC2 instances and containers to a dedicated storage volume designed for both throughput and transaction-intensive workloads at any scale. Amazon Elastic File System (supports Fargate and EC2): a fully managed, scalable, and elastic file system well suited for big data analytics, web serving and content management, application development and testing, media and entertainment workflows, database backups, and container storage. EFS stores your data redundantly across multiple Availability Zones (AZ) and offers low latency access from Kubernetes pods irrespective of the AZ in which they are running. Amazon FSx for NetApp ONTAP (supports EC2 only): Fully managed shared storage built on NetAppâ€™s popular ONTAP file system. FSx for NetApp ONTAP stores your data redundantly across multiple Availability Zones (AZ) and offers low latency access from Kubernetes pods irrespective of the AZ in which they are running. FSx for Lustre (supports EC2 only): a fully managed, high-performance file system optimized for workloads such as machine learning, high-performance computing, video processing, financial modeling, electronic design automation, and analytics. With FSx for Lustre, you can quickly create a high-performance file system linked to your S3 data repository and transparently access S3 objects as files. Amazon Simple Storage Service (supports EC2 only): is an object storage service offering industry-leading scalability, data availability, security, and performance. Customers of all sizes and industries can store and protect any amount of data for virtually any use case, such as data lakes, cloud-native applications, and mobile apps. With cost-effective storage classes and easy-to-use management features, you can optimize costs, organize data, and configure fine-tuned access controls to meet specific business, organizational, and compliance requirements.  It\u0026rsquo;s also very important to be familiar with some concepts about Kubernetes Storage:\n Volumes: On-disk files in a container are ephemeral, which presents some problems for non-trivial applications when running in containers. One problem is the loss of files when a container crashes. The kubelet restarts the container but with a clean state. A second problem occurs when sharing files between containers running together in a Pod. The Kubernetes volume abstraction solves both of these problems. Familiarity with Pods is suggested. Ephemeral Volumes are designed for these use cases. Because volumes follow the Pod\u0026rsquo;s lifetime and get created and deleted along with the Pod, Pods can be stopped and restarted without being limited to where some persistent volume is available. Persistent Volumes (PV) is a piece of storage in a cluster that has been provisioned by an administrator or dynamically provisioned using Storage Classes. It\u0026rsquo;s a resource in the cluster just like a node is a cluster resource. PVs are volume plugins like Volumes, but have a lifecycle independent of any individual Pod that uses the PV. This API object captures the details of the implementation of the storage, be that NFS, iSCSI, or a cloud-provider-specific storage system. Persistent Volume Claim (PVC) is a request for storage by a user. It\u0026rsquo;s similar to a Pod. Pods consume node resources and PVCs consume PV resources. Pods can request specific levels of resources (CPU and Memory). Claims can request specific size and access modes (e.g., they can be mounted ReadWriteOnce, ReadOnlyMany or ReadWriteMany, see AccessModes Storage Classes provides a way for administrators to describe the \u0026ldquo;classes\u0026rdquo; of storage they offer. Different classes might map to quality-of-service levels, or to backup policies, or to arbitrary policies determined by cluster administrators. Kubernetes itself is unopinionated about what classes represent. This concept is sometimes called \u0026ldquo;profiles\u0026rdquo; in other storage systems. Dynamic Volume Provisioning allows storage volumes to be created on-demand. Without dynamic provisioning, cluster administrators have to manually make calls to their cloud or storage provider to create new storage volumes, and then create PersistentVolume objects to represent them in Kubernetes. The dynamic provisioning feature eliminates the need for cluster administrators to pre-provision storage. Instead, it automatically provisions storage when it is requested by users.  "
},
{
	"uri": "/",
	"title": "Storage in Amazon EKS",
	"tags": [],
	"description": "",
	"content": "Storage in Amazon EKS Overview This workshop will provide a high level overview on how to integrate two AWS Storage services with your EKS cluster.\nContent  Introduction Prerequisites Amazon EKS Storage with Amazon EBS Amazon EKS Storage with Amazon EFS Amazon EKS Storage with Amazon S3 Cleanup resource  "
},
{
	"uri": "/2-prerequiste/2.2-modifyiamrole/",
	"title": "Modify IAM role",
	"tags": [],
	"description": "",
	"content": "In this step, we will create a IAM Role and assign it to workspace instance.\nCreate IAM role   Click IAM to navigate to IAM service.\n  Click on Role.\n  Click on Create role.   At Trusted entity type field, select AWS service.\n  At Service or use case field, select EC2.   Then, click on Next.   At Permissions policies field, select policy name AdministratorAccess.   Then, click on Next.   At Name, review, and create page, input eksworkspace-administrator at Role name field.   Then, scroll down to the end of page and click on Create role.   Assign role to workspace instance   At AWS Cloud9 interface, click on Manage EC2 instance.   You will see the created workspace instance. Then, click to select it.\n  Click on Action.\n  Click on Security.\n  Click on Modify IAM role.   Select the role name eksworkspace-administrator which was created at above steps.\n  Then, click on Update IAM role.   New IAM role was updated successfully.   Update Cloud9 configuration Cloud9 will manage IAM credentials automatically. This default configuration is currently not compatible with EKS authentication via IAM, we will need to disable this feature and use the IAM Role.\n\r  At AWS Cloud9 interface, click on AWS Cloud9.\n  Select Preferences.   At AWS Settings, disable AWS managed temporary credentials.   To ensure that temporary credentials are not saved in Cloud9, we will delete all existing credentials with the command below.\n  rm -vf ${HOME}/.aws/credentials "
},
{
	"uri": "/2-prerequiste/",
	"title": "Prerequisites",
	"tags": [],
	"description": "",
	"content": "Overview To conduct the lab, we have to prepare the Cloud9 workspace instance and create the IAM role for the Cloud9 instance.\nContent  2.1 Create Cloud9 workspace 2.2 Modify IAM Role 2.3 Installation 2.4 Create basic application  "
},
{
	"uri": "/3-eksstoragewithebs/3.2-staticprovision/",
	"title": "Static Provisioning",
	"tags": [],
	"description": "",
	"content": "In this step, we will practice how to create and consume a PersistentVolume from an existing EBS volume with static provisioning.\nVerify the Node\u0026rsquo;s Availability Zone First, we need to check which Availability Zone that our EC2 Managed Node Group Instance is placing.\n Go to EC2 Instances. Verify its Availability Zone.   In my case the Availability Zone of Node is ap-southeast-1b, so now i will create an EBS Volume at ap-southeast-1b.\nCreate an EBS volume  Go to EBS Volumes. You will see there are two volumes: default volume of Cloud9 instance and default volume of NodeGroup instance.   Click on Create volume to create new volume.   Replace to 20 at Size (GiB) field.\n  Set Availability Zone as Node\u0026rsquo;s Availability Zone. In this case is ap-southeast-1b.   Scroll down to the end of page and click on Create volume.   Edit Name of created EBS Volume fcj-ebs-strorage-eks.   Save the Volume ID to use later.   Create manifest files  At Cloud9 Terminal, create a directory name static-provision/kube-manifest.  mkdir -p static-provision/kube-manifest\rls\rls static-provision Create a file named pv.yaml inside static-provision/kube-manifest.  touch static-provision/kube-manifest/pv.yaml Open pv.yaml file, paste the below code.  apiVersion: v1\rkind: PersistentVolume\rmetadata:\rname: test-pv\rspec:\raccessModes:\r- ReadWriteOnce\rcapacity:\rstorage: 10Gi\rcsi:\rdriver: ebs.csi.aws.com\rfsType: ext4\rvolumeHandle: \u0026lt;REPLACE-WITH-YOUR-VOLUME-ID\u0026gt;  Replace with your Volume ID at volumeHandle. Then save it.   Create a file named pv-claim.yaml inside static-provision/kube-manifest.\n  touch static-provision/kube-manifest/pv-claim.yaml Open pv-claim.yaml file, paste the below code. Then save it.  apiVersion: v1\rkind: PersistentVolumeClaim\rmetadata:\rname: ebs-claim\rspec:\rstorageClassName: \u0026#34;\u0026#34; # Empty string must be explicitly set otherwise default StorageClass will be set\rvolumeName: test-pv\raccessModes:\r- ReadWriteOnce\rresources:\rrequests:\rstorage: 10Gi Create a file named pod.yaml inside static-provision/kube-manifest.  touch static-provision/kube-manifest/pod.yaml Open pod.yaml file, paste the below code. Then save it.  apiVersion: v1\rkind: Pod\rmetadata:\rname: app\rspec:\rcontainers:\r- name: app\rimage: centos\rcommand: [\u0026#34;/bin/sh\u0026#34;]\rargs: [\u0026#34;-c\u0026#34;, \u0026#34;while true; do echo $(date -u) \u0026gt;\u0026gt; /data/out.txt; sleep 5; done\u0026#34;]\rvolumeMounts:\r- name: persistent-storage\rmountPath: /data\rvolumes:\r- name: persistent-storage\rpersistentVolumeClaim:\rclaimName: ebs-claim Deploy the resources  At Cloud9 Terminal, execute the below command.  kubectl apply -f static-provision/kube-manifest Verify the result  List the Persistent Volume (PV).  kubectl get pv There is a PV named test-pv with capacity is 10GB.\nList the Persistent Volume Claim (PVC).  kubectl get pvc There is a PVC named ebs-claim, status is BOUND, volume is test-pv and capacity is 10GB.\nList the Pod.  kubectl get pod There is a Pod named app with status is Running.\nWe will validate the pod successfully wrote data to the statically provisioned volume.  kubectl exec app -- cat /data/out.txt There are a lot of data wrote to /data/out.txt file. Let take note the name of three first data to compare later. In my case is Mon May 6 17:15:04 UTC 2024, Mon May 6 17:15:09 UTC 2024 and Mon May 6 17:15:14 UTC 2024.\nNow, we will delete the pod then create another new pod to verify data in EBS volume is persistent with the new one.\nDelete the current Pod.  kubectl delete pod app 6. List all Pods again to make sure it was deleted.\nkubectl get pod Create a new Pod.  kubectl apply -f static-provision/kube-manifest List created Pod.  kubectl get pod Verify the data on /data/out.txt again.  kubectl exec app -- cat /data/out.txt As you can see, the three first of data on /data/out.txt now are still Mon May 6 17:15:04 UTC 2024, Mon May 6 17:15:09 UTC 2024 and Mon May 6 17:15:14 UTC 2024. The data is still kept while the pod is replaced with another one.\nClean up  Execute the below command to delete all created resources.  kubectl delete -f static-provision/kube-manifest Verify that all resources had been deleted successfully.  kubectl get pv,pvc,pod All of them are deleted.\n Go to EBS Volume to delete the EBS Volume named fcj-ebs-strorage-eks.\n  Select the volume named fcj-ebs-strorage-eks.\n  Click on Actions.\n  Click on Delete volume   Input delete to confirm.\n  Then, click on Delete.   "
},
{
	"uri": "/3-eksstoragewithebs/",
	"title": "Amazon EKS Storage with Amazon EBS",
	"tags": [],
	"description": "",
	"content": " "
},
{
	"uri": "/3-eksstoragewithebs/3.3-dynamicprovision/",
	"title": "Dynamic Provisioning",
	"tags": [],
	"description": "",
	"content": "Create manifest files  At Cloud9 Terminal, create a directory name dynamic-provision/kube-manifest.  mkdir -p dynamic-provision/kube-manifest Create a file named storageclass.yaml inside dynamic-provision/kube-manifest.  touch dynamic-provision/kube-manifest/storageclass.yaml Open storageclass.yaml file, paste the below code. Then save it.  apiVersion: storage.k8s.io/v1\rkind: StorageClass\rmetadata:\rname: ebs-sc\rprovisioner: ebs.csi.aws.com\rvolumeBindingMode: WaitForFirstConsumer Create a file named pv-claim.yaml inside dynamic-provision/kube-manifest.  touch dynamic-provision/kube-manifest/pv-claim.yaml Open pv-claim.yaml file, paste the below code. Then save it.  apiVersion: v1\rkind: PersistentVolumeClaim\rmetadata:\rname: ebs-claim\rspec:\raccessModes:\r- ReadWriteOnce\rstorageClassName: ebs-sc\rresources:\rrequests:\rstorage: 10Gi Create a file named pod.yaml inside dynamic-provision/kube-manifest.  touch dynamic-provision/kube-manifest/pod.yaml Open pod.yaml file, paste the below code. Then save it.  apiVersion: v1\rkind: Pod\rmetadata:\rname: app\rspec:\rcontainers:\r- name: app\rimage: centos\rcommand: [\u0026#34;/bin/sh\u0026#34;]\rargs: [\u0026#34;-c\u0026#34;, \u0026#34;while true; do echo $(date -u) \u0026gt;\u0026gt; /data/out.txt; sleep 5; done\u0026#34;]\rvolumeMounts:\r- name: persistent-storage\rmountPath: /data\rvolumes:\r- name: persistent-storage\rpersistentVolumeClaim:\rclaimName: ebs-claim Deploy resources### Deploy the resources  At Cloud9 Terminal, execute the below command.  kubectl apply -f dynamic-provision/kube-manifest Verify the result  List all created resources.  kubectl get sc,pvc,pod There is a Pod named app with status is Running, a Persistent Volume Claim named ebs-claim with status is Bound and capacity is 10Gi and a Storage Class named ebs-sc with Provider is ebs.csi.aws.com. Storage Class will dynamically create an EBS Volume with volume size defined at spec.resources.requests.storage (10Gi)..\nGo to EBS Volume to verify the result.   There is a new EBS Volume with Availability Zone same as Node\u0026rsquo;s AZ.\nWe will validate the pod successfully wrote data to the dynamically provisioned volume.  kubectl exec app -- cat /data/out.txt There are a lot of data wrote to /data/out.txt file. Let take note the name of three first data to compare later. In my case is Mon May 6 19:58:43 UTC 2024, Mon May 6 19:58:48 UTC 2024 and Mon May 6 19:58:53 UTC 2024.\nNow, we will delete the pod then create another new pod to verify data in EBS volume is persistent with the new one.\nDelete the current Pod app.  kubectl delete pod app 5. List all Pods again to make sure it was deleted.\nkubectl get pod 6. Create a new Pod.\nkubectl apply -f dynamic-provision/kube-manifest 7. List created Pod.\nkubectl get pod 8. Verify the data on /data/out.txt again.\nkubectl exec app -- cat /data/out.txt As you can see, the three first of data on /data/out.txt now are still Mon May 6 19:58:43 UTC 2024, Mon May 6 19:58:48 UTC 2024 and Mon May 6 19:58:53 UTC 2024. The data is still kept while the pod is replaced with another one.\nClean up  Execute the below command to delete all created resources.  kubectl delete -f dynamic-provision/kube-manifest Verify that all resources had been deleted successfully.  kubectl get sc,pvc,pod All of them are deleted. Because Amazon EBS Volume is created dynamically by Storage Class. So when Storage Class is deleted, Amazon EBS Volume is also removed.\nGo to EBS Volume to verify the result.   Amazon EBS Volume was removed automatically.\n"
},
{
	"uri": "/2-prerequiste/2.3-installation/",
	"title": "Installation",
	"tags": [],
	"description": "",
	"content": "In this workshop, we will install necessary tools: awscli, kubectl and eksctl.\nUpgrade awscli  Copy and paste the command below into Terminal of Cloud9 Workspace to upgrade awscli.  sudo pip install --upgrade awscli \u0026amp;\u0026amp; hash -r Install kubectl  At Cloud9 Terminal, execute those command to install kubectl.   Update the instance packages.  sudo yum update  Install kubectl.  curl -LO https://dl.k8s.io/release/v1.30.0/bin/linux/amd64/kubectl sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl Check version of kubectl.  kubectl version --client Install eksctl  At Cloud9 terminal, execute those command to install Amazon EKS.   Download and extract the latest release of eksctl with the following command.  curl --silent --location \u0026#34;https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz\u0026#34; | tar xz -C /tmp  Move the extracted binary to /usr/local/bin.  sudo mv /tmp/eksctl /usr/local/bin  Test that your installation was successful with the following command  eksctl version "
},
{
	"uri": "/2-prerequiste/2.4-createekscluster/",
	"title": "Create Amazon EKS Cluster",
	"tags": [],
	"description": "",
	"content": "In previous step, we installed necessary tools: awscli, kubectl and eksctl. Now, we will process to craete an Amazon EKS Cluster with managed Node Group as EC2 Instance.\nCreate Amazon EKS Cluster.  At Cloud9 terminal, execute the command the below to create an Amazon EKS Cluster.  eksctl create cluster --name=fcj-storage-cluster --region=ap-southeast-1 --zones=ap-southeast-1a,ap-southeast-1b --without-nodegroup Then, verify the Cluster by command.  eksctl get cluster Enable kubectl to communicate with your cluster by adding a new context to the kubectl config file.  aws eks update-kubeconfig --region=ap-southeast-1 --name=fcj-storage-cluster Then, confirm communication with your cluster by running the following command.  kubectl get svc Note: The expected output is the appearance of ClusterIP service.\nCreate and associate IAM OIDC Provider for EKS Cluster. IAM OpenID Connect (OIDC) Provider help to use some Amazon EKS add-ons, or to enable individual Kubernetes workloads to have specific AWS Identity and Access Management (IAM) permissions.\n At Cloud9 terminal, execute the command the below to create amd associate an OIDC Provider to your Amazon EKS Cluster.  eksctl utils associate-iam-oidc-provider --cluster=fcj-storage-cluster --region=ap-southeast-1 --approve To confirm created OIDC Provider, go to IAM. Navigate to Identity providers section. You will see there is a new Provider had been created.  Create Amazon EKS managed Node Group.  At Cloud9 terminal, execute the command the below to create managed Node Group and associate it to EKS Cluster.  eksctl create nodegroup --name=fcj-storage-nodegroup --cluster=fcj-storage-cluster --region=ap-southeast-1 --node-type=t3.medium --nodes=1  It will take you about 15 minutes to finish this process.   List existing nodes in cluster.\n  kubectl get nodes "
},
{
	"uri": "/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]